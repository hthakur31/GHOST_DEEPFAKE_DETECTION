#!/usr/bin/env python3
"""
Fix the deepfake detection threshold - model is too conservative
"""
import os
import sys
import django
from django.conf import settings

# Add the project root to Python path
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'deepfake_detector.settings')
django.setup()

from detector.faceforensics_model import FaceForensicsDetector
import time

def test_deepfake_detection():
    """Test the model on known deepfake videos"""
    print("üé≠ DEEPFAKE DETECTION THRESHOLD FIX")
    print("=" * 50)
    
    # Initialize detector
    detector = FaceForensicsDetector()
    
    # Test with a known deepfake video
    deepfake_video = "G:/Deefake_detection_app/dataset/manipulated_sequences/Deepfakes/c23/videos/033_097.mp4"
    
    if not os.path.exists(deepfake_video):
        print("‚ùå Test video not found")
        return
    
    print(f"üìπ Testing KNOWN DEEPFAKE: 033_097.mp4")
    print("-" * 50)
    
    # Test with current threshold
    start_time = time.time()
    result = detector.detect_video(deepfake_video)
    end_time = time.time()
    
    print("üîç CURRENT MODEL RESULT:")
    print(f"   Prediction: {result.get('prediction', 'ERROR')}")
    print(f"   Confidence: {result.get('confidence_score', 0):.3f}")
    print(f"   Real probability: {result.get('real_probability', 0):.1f}%")
    print(f"   Fake probability: {result.get('fake_probability', 0):.1f}%")
    print(f"   Threshold used: {result.get('threshold_used', 'unknown')}")
    print(f"   Processing time: {end_time - start_time:.1f}s")
    
    is_correct = result.get('prediction', '').lower() in ['deepfake', 'fake']
    if is_correct:
        print("   ‚úÖ CORRECT: Properly identified as deepfake")
    else:
        print("   ‚ùå FALSE NEGATIVE: Deepfake predicted as real!")
        print("\nüö® PROBLEM IDENTIFIED:")
        print("   The model is using overly conservative thresholds")
        print("   This causes all deepfakes to be classified as real")
    
    return result

def fix_conservative_threshold():
    """Fix the overly conservative threshold in the model"""
    print("\nüîß FIXING CONSERVATIVE THRESHOLD")
    print("=" * 50)
    
    # Read the current model file
    model_file = "G:/Deefake_detection_app/detector/faceforensics_model.py"
    
    try:
        with open(model_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # The problem is in this section of the code:
        # conservative_threshold = max(0.75, self.threshold)  # At least 75% confidence required
        # This makes it nearly impossible to detect deepfakes
        
        # Also this triple check:
        # if (weighted_fake_score > conservative_threshold and 
        #     confidence_gap > uncertainty_margin and 
        #     weighted_fake_score > 0.7):
        
        print("üîç ISSUE FOUND:")
        print("   1. Conservative threshold is set to at least 75%")
        print("   2. Triple checks require 70%+ fake probability")
        print("   3. Bias correction reduces fake probabilities by 5%")
        print("   4. Default decision is always REAL for uncertain cases")
        
        print("\nüí° RECOMMENDED FIX:")
        print("   1. Reduce conservative threshold to ~60%")
        print("   2. Remove excessive bias correction")
        print("   3. Use balanced decision making")
        print("   4. Adjust uncertainty margin")
        
        # Create a fixed version
        fixed_content = content.replace(
            "# Apply conservative threshold logic - significantly reduce false positives\n"
            "                conservative_threshold = max(0.75, self.threshold)  # At least 75% confidence required\n"
            "                uncertainty_margin = 0.05  # 5% margin for uncertainty\n"
            "                confidence_gap = abs(weighted_fake_score - weighted_real_score)\n"
            "                \n"
            "                # Only classify as FAKE if we're very confident AND there's a clear gap\n"
            "                if (weighted_fake_score > conservative_threshold and \n"
            "                    confidence_gap > uncertainty_margin and \n"
            "                    weighted_fake_score > 0.7):  # Triple check\n"
            "                    final_prediction = 1  # Fake\n"
            "                    final_confidence = weighted_fake_score\n"
            "                else:\n"
            "                    # Default to REAL for uncertain cases (reduces false positives)\n"
            "                    final_prediction = 0  # Real\n"
            "                    final_confidence = weighted_real_score",
            
            "# Apply balanced threshold logic - avoid both false positives and false negatives\n"
            "                balanced_threshold = self.threshold  # Use the configured threshold (default 0.5)\n"
            "                uncertainty_margin = 0.02  # Reduced margin for better sensitivity\n"
            "                confidence_gap = abs(weighted_fake_score - weighted_real_score)\n"
            "                \n"
            "                # Balanced decision: use the higher score with confidence gap check\n"
            "                if weighted_fake_score > weighted_real_score:\n"
            "                    if weighted_fake_score > balanced_threshold and confidence_gap > uncertainty_margin:\n"
            "                        final_prediction = 1  # Fake\n"
            "                        final_confidence = weighted_fake_score\n"
            "                    else:\n"
            "                        # If not confident enough, default to the higher score\n"
            "                        final_prediction = 1 if weighted_fake_score > 0.5 else 0\n"
            "                        final_confidence = max(weighted_fake_score, weighted_real_score)\n"
            "                else:\n"
            "                    if weighted_real_score > balanced_threshold and confidence_gap > uncertainty_margin:\n"
            "                        final_prediction = 0  # Real\n"
            "                        final_confidence = weighted_real_score\n"
            "                    else:\n"
            "                        # If not confident enough, default to the higher score\n"
            "                        final_prediction = 0 if weighted_real_score > 0.5 else 1\n"
            "                        final_confidence = max(weighted_fake_score, weighted_real_score)"
        )
        
        # Also reduce the bias correction
        fixed_content = fixed_content.replace(
            "# Apply bias correction - the model seems to have a systematic bias toward fake\n"
            "                # If probabilities are very close to 50%, apply conservative bias toward real\n"
            "                bias_correction = 0.05  # 5% bias correction toward real",
            
            "# Apply minimal bias correction for balance\n"
            "                # Slight correction to account for training bias\n"
            "                bias_correction = 0.02  # 2% bias correction toward real (reduced)"
        )
        
        # Write the fixed content
        with open(model_file, 'w', encoding='utf-8') as f:
            f.write(fixed_content)
        
        print("‚úÖ THRESHOLD FIX APPLIED!")
        print("   - Reduced conservative threshold from 75% to balanced")
        print("   - Reduced bias correction from 5% to 2%")
        print("   - Implemented balanced decision making")
        print("   - Reduced uncertainty margin from 5% to 2%")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error fixing threshold: {e}")
        return False

def test_after_fix():
    """Test the model after applying the fix"""
    print("\nüß™ TESTING AFTER FIX")
    print("=" * 30)
    
    # Restart Django to reload the module
    from importlib import reload
    import detector.faceforensics_model
    reload(detector.faceforensics_model)
    from detector.faceforensics_model import FaceForensicsDetector
    
    # Initialize new detector with fixed logic
    detector = FaceForensicsDetector()
    
    # Test with the same deepfake video
    deepfake_video = "G:/Deefake_detection_app/dataset/manipulated_sequences/Deepfakes/c23/videos/033_097.mp4"
    
    if not os.path.exists(deepfake_video):
        print("‚ùå Test video not found")
        return
    
    print(f"üìπ Testing FIXED MODEL: 033_097.mp4")
    print("-" * 40)
    
    start_time = time.time()
    result = detector.detect_video(deepfake_video)
    end_time = time.time()
    
    print("üîç FIXED MODEL RESULT:")
    print(f"   Prediction: {result.get('prediction', 'ERROR')}")
    print(f"   Confidence: {result.get('confidence_score', 0):.3f}")
    print(f"   Real probability: {result.get('real_probability', 0):.1f}%")
    print(f"   Fake probability: {result.get('fake_probability', 0):.1f}%")
    print(f"   Threshold used: {result.get('threshold_used', 'unknown')}")
    print(f"   Processing time: {end_time - start_time:.1f}s")
    
    is_correct = result.get('prediction', '').lower() in ['deepfake', 'fake']
    if is_correct:
        print("   ‚úÖ SUCCESS: Deepfake now correctly identified!")
    else:
        print("   ‚ö†Ô∏è  Still not detecting deepfakes - may need further adjustment")
    
    return result

if __name__ == '__main__':
    print("üöÄ DEEPFAKE DETECTION THRESHOLD FIX")
    print("=" * 60)
    
    # Test current model
    current_result = test_deepfake_detection()
    
    # Apply fix if needed
    if current_result and current_result.get('prediction', '').lower() not in ['deepfake', 'fake']:
        fix_conservative_threshold()
        
        # Test after fix
        test_after_fix()
    else:
        print("\n‚úÖ Model is already working correctly!")
    
    print("\nüéØ SUMMARY:")
    print("   The model was too conservative and defaulted to 'Real' for everything")
    print("   Fixed by adjusting thresholds and reducing bias correction")
    print("   Model should now correctly identify both real and fake videos")
